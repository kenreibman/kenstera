---
phase: 03-agent-prompt
plan: 02
type: execute
wave: 2
depends_on:
  - 03-01
files_modified: []
autonomous: false
requirements:
  - AGNT-01
  - AGNT-02
  - AGNT-04
  - AGNT-05

must_haves:
  truths:
    - "The update script runs successfully and updates the Retell LLM and agent without errors"
    - "A test call with a name reaches the caller's phone and Kate greets them by name"
    - "Kate walks through all 4 intake questions in a natural conversational flow"
    - "Kate ends the call cleanly after the intake demo without pitching or asking for feedback"
    - "The call completes naturally before the 120s hard cap fires"
  artifacts: []
  key_links:
    - from: "scripts/update-agent-prompt.ts"
      to: "Retell LLM API"
      via: "client.llm.update() call"
      pattern: "LLM updated"
    - from: "app/api/demo-call/route.ts"
      to: "Retell Call API"
      via: "createPhoneCall with retell_llm_dynamic_variables"
      pattern: "caller_name"
---

<objective>
Run the update script to push the Kate prompt to Retell, then verify the agent works correctly through real test calls.

Purpose: Validate that the prompt engineering actually produces the intended caller experience -- greeting by name, phone screening bypass, intake simulation, guardrails, and clean call termination. Code alone cannot verify voice agent behavior; real calls are the only valid test.

Output: Confirmed working agent with at least 5 successful test calls demonstrating correct behavior.
</objective>

<execution_context>
@C:/Users/DESKTOP/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/DESKTOP/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-agent-prompt/03-CONTEXT.md
@.planning/phases/03-agent-prompt/03-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run update script and verify Retell resources updated</name>
  <files></files>
  <action>
Run the update-agent-prompt.ts script to push the Kate prompt and voicemail config to Retell:

```bash
npx tsx --tsconfig tsconfig.scripts.json scripts/update-agent-prompt.ts
```

Expected output:
- "Step 1/2: Updating Retell LLM prompt..."
- "LLM updated: begin_message + general_prompt + end_call tool"
- "Step 2/2: Updating agent voicemail config..."
- "Agent updated: voicemail detection enabled (hangup on voicemail)"
- "Agent prompt update complete."

If the script fails:
- Auth error → check RETELL_API_KEY in .env.local
- Missing LLM ID → check RETELL_LLM_ID in .env.local
- Missing Agent ID → check RETELL_AGENT_ID in .env.local
- SDK type error → check retell-sdk version matches 5.2.0

After successful run, verify the update took effect by retrieving the LLM:
```bash
npx tsx -e "
const Retell = require('retell-sdk').default;
const fs = require('fs');
const path = require('path');
const envPath = path.join(process.cwd(), '.env.local');
const envContent = fs.readFileSync(envPath, 'utf8');
for (const line of envContent.split('\n')) {
  const t = line.trim();
  if (!t || t.startsWith('#')) continue;
  const eq = t.indexOf('=');
  if (eq > 0) { const k = t.slice(0,eq).trim(); const v = t.slice(eq+1).trim(); if (!process.env[k]) process.env[k] = v; }
}
const c = new Retell({ apiKey: process.env.RETELL_API_KEY });
c.llm.retrieve(process.env.RETELL_LLM_ID).then(llm => {
  console.log('begin_message:', llm.begin_message);
  console.log('has general_tools:', llm.general_tools?.length > 0);
  console.log('has end_call tool:', llm.general_tools?.some(t => t.type === 'end_call'));
  console.log('model:', llm.model);
});
"
```

Verify output shows:
- begin_message contains "Kate" and "{{caller_name}}"
- has general_tools: true
- has end_call tool: true
- model: gpt-4.1
  </action>
  <verify>
1. Script exits with code 0 (no errors)
2. Console output shows both "LLM updated" and "Agent updated" messages
3. LLM retrieve confirms begin_message contains "Kate" and "{{caller_name}}"
4. LLM retrieve confirms end_call tool is present in general_tools
  </verify>
  <done>
- Update script ran successfully without errors
- Retell LLM has the Kate persona prompt with begin_message, general_prompt, and end_call tool
- Retell agent has voicemail detection enabled with hangup action
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Verify agent behavior via real test calls</name>
  <files></files>
  <action>
CHECKPOINT: Human verification required. Kate intake specialist agent has been deployed — single-path voice agent that greets callers by name, sets up a car accident intake scenario, asks 4 intake questions, and ends the call cleanly. The agent has guardrails for off-topic and abusive callers, and voicemail detection that hangs up on voicemail.

Make at least 5 real test calls using curl to trigger the demo-call API. Use your own phone number.

**Test call command (replace values):**
```bash
curl -X POST http://localhost:3000/api/demo-call \
  -H "Content-Type: application/json" \
  -d '{"phone": "+1XXXXXXXXXX", "name": "John", "recaptchaToken": "test-token"}'
```

Note: reCAPTCHA verification will reject "test-token" in production. For testing, you may need to:
- Use a real reCAPTCHA token, OR
- Temporarily bypass reCAPTCHA in dev (if a dev bypass exists), OR
- Use the Retell dashboard to test calls directly with the updated LLM

**Verification checklist (check each across your test calls):**

1. **Greeting (AGNT-01):** Kate says "Hi, my name is Kate, I'm looking to speak with [your name]" — your actual name, not "{{caller_name}}" literally
2. **Phone screening:** If your phone has screening, Kate's opening line gets past it
3. **Demo framing:** After you confirm identity, Kate explains the car accident scenario
4. **Intake questions (AGNT-02):** Kate asks all 4 questions one at a time: what happened, when, injuries, fault
5. **Brief acknowledgments:** Between questions, Kate says short responses (3-6 words: "Got it", "Understood", etc.)
6. **Production disclaimer:** After 4th question, Kate mentions "in a real scenario" more questions would follow
7. **Clean closing:** Kate says something like "That's the end of the demo" and ends the call — no pitch, no CTA, no feedback request
8. **Duration (AGNT-05):** Call completes naturally in ~60-90 seconds, well before the 120s cap
9. **Guardrail test (AGNT-04):** In at least one call, say something off-topic. Kate should redirect once, then end call if you persist
10. **No AI disclosure:** Kate never says she is AI, a bot, or an assistant
  </action>
  <verify>User confirms all 10 verification checks pass across at least 5 real test calls</verify>
  <done>User types "approved" confirming agent behavior meets AGNT-01 through AGNT-05 requirements</done>
  <resume-signal>Type "approved" or describe issues found during test calls</resume-signal>
</task>

</tasks>

<verification>
1. Update script ran without errors and Retell resources are confirmed updated
2. At least 5 real test calls completed successfully
3. Kate greets by name, runs intake, and ends cleanly in every call
4. Guardrail behavior confirmed (off-topic redirect + escalation, abuse termination)
5. No call hit the 120s hard cap (all completed naturally before cutoff)
</verification>

<success_criteria>
- Agent prompt is live on Retell and verified via LLM retrieve
- Real test calls demonstrate correct greeting, intake flow, closing, and guardrails
- User approves the agent behavior as meeting AGNT-01 through AGNT-05 requirements
</success_criteria>

<output>
After completion, create `.planning/phases/03-agent-prompt/03-02-SUMMARY.md`
</output>
